{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3492511d-7fb2-4480-a73c-ad82b8200fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe9db2d-1dc7-4d40-bb9c-5a44ebd41289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning \n",
    "#classifier, which uses proximity to make classifications or predictions about the grouping of an individual data\n",
    "#point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb34042c-2cb2-41e5-9a88-a63a74228b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55e5217-621e-49f9-a49d-24a8c24f3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of k will largely depend on the input data as data with more outliers or noise will likely perform\n",
    "#better with higher values of k. Overall, it is recommended to have an odd number for k to avoid ties in \n",
    "#classification, and cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382234f5-da10-4892-a43e-a3e8ce7192e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69d26bd-219a-42f3-a982-3325989252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most basic difference between classification and regression is that classification algorithms are used to\n",
    "#analyze discrete values, whereas regression algorithms analyze continuous real values. The output variable must \n",
    "#be either continuous nature or real value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181e617e-eb37-4578-b015-f54734105656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f8f918-df6f-4595-bd17-53946a982ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of nearest neighbours (K values).\n",
    "#Compute the distance between test sample and all the training samples.\n",
    "#Sort the distance and determine nearest neighbours based on the K-th minimum distance.\n",
    "#Assemble the categories of the nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c61db7-904b-4f6f-92c6-5c7788131ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be263007-b68e-449a-ae65-af9e6d2c078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional\n",
    "#data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size\n",
    "#of your data set must also grow exponentially in order to keep the same density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5609f62-1d97-4bc5-87df-45575a93f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9474a88b-cfa7-4fb0-89aa-aba4e542648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea in kNN methods is to identify 'k' samples in the dataset that are similar or close in the space. \n",
    "#Then we use these 'k' samples to estimate the value of the missing data points. Each sample's missing values are\n",
    "#imputed using the mean value of the 'k'-neighbors found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595b48ef-67e0-41f6-8a6b-c05cf070579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7.Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "#which type of problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "501b9c7c-2ef3-4481-a075-2ed5abff178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Regressor vs classifier\n",
    "#The key differences are: KNN regression tries to predict the value of the output variable by using a local \n",
    "#average. KNN classification attempts to predict the class to which the output variable belong by computing \n",
    "#the local probability.\n",
    "#The KNN algorithm can compete with the most accurate models because it makes highly accurate predictions. \n",
    "#Therefore, you can use the KNN algorithm for applications that require high accuracy but that do not require a \n",
    "#human-readable model. The quality of the predictions depends on the distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eadbabc-b99d-4674-b528-c5617d014ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8 What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "#and how can these be addressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b8119a-0a56-4bd7-810d-73258aee7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The KNN uses neighborhood classification as the predication value of the new query. It has advantages - \n",
    "#nonparametric architecture, simple and powerful, requires no traning time, but it also has disadvantage -\n",
    "#memory intensive, classification and estimation are slow.\n",
    "\n",
    "#It's easy to understand and simple to implement.\n",
    "#It can be used for both classification and regression problems.\n",
    "#It's ideal for non-linear data since there's no assumption about underlying data.\n",
    "#It can naturally handle multi-class cases.\n",
    "#It can perform well with enough representative data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb8aecab-0e8c-4d51-8a2d-b5a4084ff621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48bbc459-12e3-460f-8f3a-73a104e1ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan distance is usually preferred over the more common Euclidean distance when there is high dimensionality\n",
    "#in the data. Hamming distance is used to measure the distance between categorical variables, and the Cosine \n",
    "#distance metric is mainly used to find the amount of similarity between two data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0bde263-2380-4583-a63a-349206f554f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a13bb-aa32-4014-8497-4ef33085bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling is essential for machine learning algorithms that calculate distances between data.\n",
    "#If not scaled, the feature with a higher value range starts dominating when calculating distances.\n",
    "KNN which uses Euclidean distance is one such algorithm which essentially require scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
